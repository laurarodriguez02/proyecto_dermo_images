{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hKZ5LW0_Svnj",
        "9pTQX4kYSvnp",
        "7VKKgKbuSvnt",
        "YxSw1NNRSvo-",
        "s8MgAF6xSvp8",
        "MciAU8UGSvqN",
        "gQWk1bJYSvrR",
        "LK3EgL1gSvrq",
        "9AVhJhoRSvr7",
        "P9r5QNCzSvsB",
        "l8vYJM7TSvtE",
        "DaJZx6bcSvtQ"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaQoer9F0rr7"
      },
      "source": [
        "\n",
        "#*Pilotaje para la prueba de tamizaje para evaluación de lesiones dermatológicas como ayuda diagnostica a través de inteligencia artificial.*\n",
        "\n",
        "**Cuál es el objetivo?**\n",
        "\n",
        "Crear una herramienta en línea que pueda indicar a los médicos y técnicos de laboratorio los tres diagnósticos de mayor probabilidad para una determinada lesión de piel. Esto les ayudará a identificar rápidamente a los pacientes de alta prioridad y a acelerar su flujo de trabajo. La aplicación debería producir un resultado en menos de 3 segundos. Para asegurar la privacidad, las imágenes deben ser pre-procesadas y analizadas localmente y nunca ser subidas a un servidor externo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDUwcEVQzBBv"
      },
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "371731306c3e504b191979706e826c247def88dc",
        "id": "EQxKH051SvnU"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(101)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(101)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import keras\n",
        "#from keras import backend as K\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d3f6843b78793e1c047ca6909a7449dc9bfc3f1c",
        "id": "-as-x4UzSvnd"
      },
      "source": [
        "**LABELS**<br>\n",
        "\n",
        "Excerpts from the paper:<br>\n",
        "> The HAM10000 Dataset: A Large Collection of Multi-Source Dermatoscopic Images of Common Pigmented Skin Lesions<br>\n",
        "https://arxiv.org/abs/1803.10417\n",
        "\n",
        "\n",
        "\n",
        " **nv**<br>\n",
        " Los nevos melanocíticos son neoplasias benignas de los melanocitos y se presentan en una miríada de variantes, todas ellas incluidas en nuestra serie. Las variantes pueden diferir significativamente desde el punto de vista dermatoscópico.<br>\n",
        " *[6705 images]*\n",
        "\n",
        " **mel**<br>\n",
        " El melanoma es una neoplasia maligna derivada de los melanocitos que puede aparecer en diferentes variantes. Si se extirpa en una fase temprana, puede curarse mediante una simple escisión quirúrgica. Los melanomas pueden ser invasivos o no invasivos (in situ). Incluimos todas las variantes de melanoma, incluido el melanoma in situ, pero excluimos el melanoma no pigmentado, subungueal, ocular o de las mucosas.<br>*[1113 images]*\n",
        "\n",
        "\n",
        "**bkl**<br>\n",
        " La \"queratosis benigna\" es una clase genérica que incluye la queratosis seborreica (\"verruga senil\"), el lentigo solar -que puede considerarse una variante plana de la queratosis seborreica- y la queratosis de tipo liquen plano (LPLK), que corresponde a una queratosis seborreica o a un lentigo solar con inflamación y regresión [22]. Los tres subgrupos pueden tener un aspecto dermatoscópico diferente, pero los hemos agrupado porque son similares desde el punto de vista biológico y a menudo se presentan bajo el mismo término genérico desde el punto de vista histopatológico. Desde el punto de vista dermatoscópico, las queratosis similares al liquen plano son especialmente difíciles porque pueden mostrar características morfológicas que imitan al melanoma [23] y a menudo se les practica una biopsia o una extirpación por motivos de diagnóstico. .<br>\n",
        "*[1099 images]*\n",
        "\n",
        "**bcc**<br>\n",
        "El carcinoma basocelular es una variante común del cáncer de piel epitelial que rara vez hace metástasis, pero que crece destructivamente si no se trata. Aparece en diferentes variantes morfológicas (plano, nodular, pigmentado, quístico, etc.) [21], todas ellas incluidas en este conjunto.<br>\n",
        "*[514 images]*\n",
        "\n",
        "**akiec**<br>\n",
        "Las queratosis actínicas (queratosis solares) y el carcinoma intraepitelial (enfermedad de Bowen) son variantes comunes no invasivas del carcinoma de células escamosas que pueden tratarse localmente sin cirugía. Algunos autores los consideran precursores de los carcinomas de células escamosas y no carci- nomas propiamente dichos. Sin embargo, hay acuerdo en que estas lesiones pueden evolucionar hacia un carcinoma de células escamosas invasivo, que normalmente no está pigmentado. Ambas neoplasias suelen mostrar escamas en la superficie y suelen carecer de pigmento. Las queratosis actínicas son más comunes en la cara y la enfermedad de Bowen es más común en otras zonas del cuerpo. Dado que ambos tipos son producidos por la luz ultravioleta, la piel circundante suele estar muy dañada por el sol, excepto en los casos de la enfermedad de Bowen, que están causados por la infección del virus del papiloma humano y no por la luz ultravioleta. Existen variantes pigmentadas para la enfermedad de Bowen [19] y para las queratosis actínicas [20]. Ambas se incluyen en este conjunto.<br>*[327 images]*\n",
        "\n",
        "\n",
        "**vasc**<br>\n",
        "Las lesiones vasculares de la piel en el conjunto de datos van desde los angiomas de cereza hasta los angioqueratomas [25] y los granulomas piogénicos [26]. Las hemorragias también se incluyen en esta categoría.<br>\n",
        "*[142 images]*\n",
        "\n",
        "**df**<br>\n",
        "El dermatofibroma es una lesión cutánea benigna considerada como una proliferación benigna o una reacción inflamatoria a un traumatismo mínimo. Es de color marrón y a menudo muestra una zona central de fibrosis dermatoscópica [24].<br>*[115 images]*\n",
        "\n",
        "\n",
        "<br>*[Total images = 10015]*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF_SdkzGWKzr"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "#before importing the dataset we want to use this code\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir data\n",
        "!kaggle datasets download kmader/skin-cancer-mnist-ham10000 -p data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q-JMR5BWVLN"
      },
      "source": [
        "# Unzip the whole zipfile into /content/data\n",
        "!unzip -o data/skin-cancer-mnist-ham10000.zip -d data\n",
        "# Quietly unzip the image files\n",
        "#!unzip -o data/HAM10000_images_part_1.zip -d data\n",
        "#!unzip -o data/HAM10000_images_part_2.zip -d data\n",
        "# Tell me how many files I unzipped///\n",
        "!echo files in /content/data: `ls data | wc -l`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d5a0a200bfc57c5489eaa930255d9420a7d01c47",
        "id": "A7O3Y1PqSvne"
      },
      "source": [
        "os.listdir('./data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "086162161ba405b800863e7d545b5917e5205984",
        "id": "hKZ5LW0_Svnj"
      },
      "source": [
        "### Crear la estructura de directorios\n",
        "\n",
        "En estas carpetas almacenaremos las imágenes que posteriormente alimentarán los generadores de Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d24ef21f9f2359b8bf6b3e7a0b8ab5a43daaf566",
        "id": "Q8_6ZfUJSvnk"
      },
      "source": [
        "# Create a new directory\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "\n",
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 7 folders inside 'base_dir':\n",
        "\n",
        "# train_dir\n",
        "    # nv\n",
        "    # mel\n",
        "    # bkl\n",
        "    # bcc\n",
        "    # akiec\n",
        "    # vasc\n",
        "    # df\n",
        "\n",
        "# val_dir\n",
        "    # nv\n",
        "    # mel\n",
        "    # bkl\n",
        "    # bcc\n",
        "    # akiec\n",
        "    # vasc\n",
        "    # df\n",
        "\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
        "# Inside each folder we create seperate folders for each class\n",
        "\n",
        "# create new folders inside train_dir\n",
        "nv = os.path.join(train_dir, 'nv')\n",
        "os.mkdir(nv)\n",
        "mel = os.path.join(train_dir, 'mel')\n",
        "os.mkdir(mel)\n",
        "bkl = os.path.join(train_dir, 'bkl')\n",
        "os.mkdir(bkl)\n",
        "bcc = os.path.join(train_dir, 'bcc')\n",
        "os.mkdir(bcc)\n",
        "akiec = os.path.join(train_dir, 'akiec')\n",
        "os.mkdir(akiec)\n",
        "vasc = os.path.join(train_dir, 'vasc')\n",
        "os.mkdir(vasc)\n",
        "df = os.path.join(train_dir, 'df')\n",
        "os.mkdir(df)\n",
        "\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "nv = os.path.join(val_dir, 'nv')\n",
        "os.mkdir(nv)\n",
        "mel = os.path.join(val_dir, 'mel')\n",
        "os.mkdir(mel)\n",
        "bkl = os.path.join(val_dir, 'bkl')\n",
        "os.mkdir(bkl)\n",
        "bcc = os.path.join(val_dir, 'bcc')\n",
        "os.mkdir(bcc)\n",
        "akiec = os.path.join(val_dir, 'akiec')\n",
        "os.mkdir(akiec)\n",
        "vasc = os.path.join(val_dir, 'vasc')\n",
        "os.mkdir(vasc)\n",
        "df = os.path.join(val_dir, 'df')\n",
        "os.mkdir(df)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "4ae8d37fdee293aaffa71a79019dd7277f8288fc",
        "id": "9pTQX4kYSvnp"
      },
      "source": [
        "### Crear conjuntos de entrenamiento y val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "268503398ef61904e05a2c0b0667d589f08a19a8",
        "id": "A0BuHu4VSvnp"
      },
      "source": [
        "df_data = pd.read_csv('./data/HAM10000_metadata.csv')\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c46ea5967e095d31dcf144b6f57f0343878fa432",
        "id": "7VKKgKbuSvnt"
      },
      "source": [
        "### Crear un conjunto de val estratificado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "53e4b7b152ed831a7d7516156ac300c0e6985ffc",
        "id": "cT8aUlubSvnu"
      },
      "source": [
        "# this will tell us how many images are associated with each lesion_id\n",
        "df = df_data.groupby('lesion_id').count()\n",
        "\n",
        "# now we filter out lesion_id's that have only one image associated with it\n",
        "df = df[df['image_id'] == 1]\n",
        "\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "24720fe3ea9f2f4b571abd09ecfbb931d6429852",
        "id": "XzgrQXFwSvn2"
      },
      "source": [
        "# here we identify lesion_id's that have duplicate images and those that have only\n",
        "# one image.\n",
        "\n",
        "def identify_duplicates(x):\n",
        "\n",
        "    unique_list = list(df['lesion_id'])\n",
        "\n",
        "    if x in unique_list:\n",
        "        return 'no_duplicates'\n",
        "    else:\n",
        "        return 'has_duplicates'\n",
        "\n",
        "# create a new colum that is a copy of the lesion_id column\n",
        "df_data['duplicates'] = df_data['lesion_id']\n",
        "# apply the function to this new column\n",
        "df_data['duplicates'] = df_data['duplicates'].apply(identify_duplicates)\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "08b7eef3e0ac4112f63b8fb26ce19d55483cbc04",
        "id": "f5mOqjLnSvn-"
      },
      "source": [
        "df_data['duplicates'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "995445dfda2745165a53e61f42615104b951d4af",
        "id": "1E3SYUv1SvoD"
      },
      "source": [
        "# now we filter out images that don't have duplicates\n",
        "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
        "\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "39fde25b59a9452cf700c5b2ff82cc7cc45c4a33",
        "id": "JPqOxzomSvoO"
      },
      "source": [
        "# now we create a val set using df because we are sure that none of these images\n",
        "# have augmented duplicates in the train set\n",
        "y = df['dx']\n",
        "\n",
        "_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=y)\n",
        "\n",
        "df_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "1df37227f7ce993d054ed5b8480ee724696fc210",
        "id": "oeMRbuhqSvoU"
      },
      "source": [
        "df_val['dx'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "08c5e12fcef2da5f49267a6b82161b2c52c2b20a",
        "id": "iNLeWBKsSvoZ"
      },
      "source": [
        "### Crear un conjunto de entrenamiento  que excluya las imágenes que están en el conjunto val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "03715a6cf5aeb6430ee144a84eb10dde216c0fb9",
        "id": "tEkcC-_bSvod"
      },
      "source": [
        "# This set will be df_data excluding all rows that are in the val set\n",
        "\n",
        "# This function identifies if an image is part of the train\n",
        "# or val set.\n",
        "def identify_val_rows(x):\n",
        "    # create a list of all the lesion_id's in the val set\n",
        "    val_list = list(df_val['image_id'])\n",
        "\n",
        "    if str(x) in val_list:\n",
        "        return 'val'\n",
        "    else:\n",
        "        return 'train'\n",
        "\n",
        "# identify train and val rows\n",
        "\n",
        "# create a new colum that is a copy of the image_id column\n",
        "df_data['train_or_val'] = df_data['image_id']\n",
        "# apply the function to this new column\n",
        "df_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n",
        "\n",
        "# filter out train rows\n",
        "df_train = df_data[df_data['train_or_val'] == 'train']\n",
        "\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4b976a9018b1bd2dc0522c68339c5861534a1571",
        "id": "jEGgS3XESvol"
      },
      "source": [
        "df_train['dx'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "1581d5a3e86f9673ae175102112017e30229bc37",
        "id": "PvJzGftmSvow"
      },
      "source": [
        "df_val['dx'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8812ad87c4fa18d2d82497df42c3895c7f10bc39",
        "id": "YxSw1NNRSvo-"
      },
      "source": [
        "### Transferencia de las imágenes a las carpetas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4acee2b7879762e50b52df118a9b691515fe7ac0",
        "id": "Pz51DrcwSvpA"
      },
      "source": [
        "# Set the image_id as the index in df_data\n",
        "df_data.set_index('image_id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "eca02fbf066c8124d0cb465295bbd2593f5f045a",
        "id": "c7H5pSbPSvpL"
      },
      "source": [
        "# Get a list of images in each of the two folders\n",
        "folder_1 = os.listdir('./data/HAM10000_images_part_1')\n",
        "#folder_2 = os.listdir('../input/ham10000_images_part_2')\n",
        "\n",
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('./data/HAM10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\"\"\"\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('../input/ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "\"\"\"\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('./data/HAM10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\"\"\"\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('../input/ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "5a4847c4cc799c23e57bf2531d92117cb95e1b07",
        "id": "HtJRX97fSvpT"
      },
      "source": [
        "# check how many train images we have in each folder\n",
        "\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "fd05c08cbfa00418dc333f5b67d1ff6e98aa973e",
        "id": "iDLMa4zGSvpa"
      },
      "source": [
        "# check how many val images we have in each folder\n",
        "\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cebcb5242ff542efb03be5086bf3796bea70c591",
        "id": "hvTCSuhiSvpi"
      },
      "source": [
        "### Copiar las imágenes del tren en aug_dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8fe970d74e9d5a284420af4ad37d8aae89dc1c15",
        "id": "eFGRAo4CSvpj"
      },
      "source": [
        "# note that we are not augmenting class 'nv'\n",
        "class_list = ['mel','bkl','bcc','akiec','vasc','df']\n",
        "\n",
        "for item in class_list:\n",
        "\n",
        "    # We are creating temporary directories here because we delete these directories later\n",
        "    # create a base dir\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "    # create a dir within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # list all images in that directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n",
        "    for fname in img_list:\n",
        "            # source path to image\n",
        "            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "            # destination path to image\n",
        "            dst = os.path.join(img_dir, fname)\n",
        "            # copy the image from the source to the destination\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        #brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                           save_to_dir=save_path,\n",
        "                                           save_format='jpg',\n",
        "                                                    target_size=(224,224),\n",
        "                                                    batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "\n",
        "    ###########\n",
        "\n",
        "    num_aug_images_wanted = 6000 # total number of images we want to have in each class\n",
        "\n",
        "    ###########\n",
        "\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
        "\n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0,num_batches):\n",
        "\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b9bbc56bd25441150d2430dca2b07d8ebae57d95",
        "id": "f5AwOq9WSvpo"
      },
      "source": [
        "# Check how many train images we now have in each folder.\n",
        "# This is the original images plus the augmented images.\n",
        "\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "21de03bdc63ecf78cc061d364d14d3216a544b43",
        "id": "-cq4UBRrSvpt"
      },
      "source": [
        "# Check how many val images we have in each folder.\n",
        "\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "767cb7d35e301369f020cdbb705da1620ba8e594",
        "id": "1NzV0gKTSvpx"
      },
      "source": [
        "### Visualizar 50 imágenes aumentadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "5f0e13a8455af926fe449e1b3ea818b704724202",
        "id": "j_8IBc4cSvpx"
      },
      "source": [
        "# plots images with labels within jupyter notebook\n",
        "# source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n",
        "\n",
        "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "plots(imgs, titles=None) # titles=labels will display the image labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "c3e2126a39c06568a1f95da2ab42353447d1be20",
        "id": "iH_5YI8fSvp2"
      },
      "source": [
        "# End of Data Preparation\n",
        "### ===================================================================================== ###\n",
        "# Start of Model Building"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "_uuid": "32dad10b7c104d2baa972da8cbadc7d6038af05c",
        "id": "s8MgAF6xSvp8"
      },
      "source": [
        "### Configurar los generadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "aa1041d69b0e8313324b91e3e9475799e1ad61c2",
        "id": "obsvXuJFSvp9"
      },
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "image_size = 224\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d0e5aede7139196b0d4e1344b278e7621f005550",
        "id": "Zk-kczoUSvqG"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "    tensorflow.keras.applications.mobilenet.preprocess_input)\n",
        "\n",
        "train_batches = datagen.flow_from_directory(train_path,\n",
        "                                            target_size=(image_size,image_size),\n",
        "                                            batch_size=train_batch_size)\n",
        "\n",
        "valid_batches = datagen.flow_from_directory(valid_path,\n",
        "                                            target_size=(image_size,image_size),\n",
        "                                            batch_size=val_batch_size)\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_batches = datagen.flow_from_directory(valid_path,\n",
        "                                            target_size=(image_size,image_size),\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8ee4ee41f1b16083bd9fc20ee9dec40acccc97dd",
        "id": "MciAU8UGSvqN"
      },
      "source": [
        "### Implementar y transformar el modelo de MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ad582cb8ea0ca2d563fc367aa89b7edfafc1a57f",
        "id": "fVLI60YRSvqO"
      },
      "source": [
        "# create a copy of a mobilenet model\n",
        "mobile = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "960449ec7ecdda92ba733ad23b00b7be605f3d4b",
        "_kg_hide-output": true,
        "id": "yKoQ2JPqSvqX"
      },
      "source": [
        "mobile.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar el modelo MobileNet\n",
        "mobile = MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "#congelar todas las capas base del modelo MobileNet\n",
        "for layer in mobile.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Obtener la salida de la penúltima capa del modelo MobileNet\n",
        "# x = mobile.layers[len(mobile.layers)-1].output\n",
        "x = mobile.layers[-1].output\n",
        "\n",
        "# Añadir una capa de Dropout para regularización\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Añadir una capa densa para las predicciones\n",
        "predictions = Dense(7, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "# predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "#Generar callbacks\n",
        "my_callbacks = [\n",
        "    tensorflow.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tensorflow.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n",
        "]\n",
        "\n",
        "# Construir el modelo final\n",
        "model = Model(inputs=mobile.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ex3f5t93ZYEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a9d74e44630c3d07a596460c8fbfda3ae7cae1e9",
        "id": "FIegM23FSvrF"
      },
      "source": [
        "# We need to choose how many layers we actually want to be trained.\n",
        "\n",
        "# Here we are freezing the weights of all layers except the\n",
        "# last 23 layers in the new model.\n",
        "# The last 23 layers of the model will be trained.\n",
        "\n",
        "for layer in model.layers:\n",
        "    if layer.name != 'input_':\n",
        "        last_char = layer.name[-1]\n",
        "        if last_char.isdigit() and int(last_char) % 2 == 0:\n",
        "            layer.trainable = False\n",
        "\n",
        "for layer in model.layers:\n",
        "  print (layer.name,\n",
        "         layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(layer.name)"
      ],
      "metadata": {
        "id": "G5c6M0whK0eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "13cf63a53e5195cb8a9725d2506c71108bc478b9",
        "id": "gQWk1bJYSvrR"
      },
      "source": [
        "### Entrenamiento del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "915f30a4f5ad369713bcb8e3bfa438219d6c8ef7",
        "id": "Jiw5-8f1SvrT"
      },
      "source": [
        "# Define Top2 and Top3 Accuracy\n",
        "\n",
        "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "2013ff1abae70fed845af94e7ab3d95cefad0d61",
        "id": "Dnb3LgyjSvrY"
      },
      "source": [
        "# model.compile(Adam(lr=0.01), loss='categorical_crossentropy',\n",
        "#               metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "62e7a784a33d4c868f49a3ef1f9acbc7186e3338",
        "id": "KohslovgSvrb"
      },
      "source": [
        "# Get the labels that are associated with each index\n",
        "print(valid_batches.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3001857c9a3c2b15c2343627e340eb1ae858fae9",
        "id": "z5xu-Us5Svrg"
      },
      "source": [
        "# Add weights to try to make the model more sensitive to melanoma\n",
        "\n",
        "class_weights={\n",
        "    0: 1.0, # akiec\n",
        "    1: 1.0, # bcc\n",
        "    2: 1.0, # bkl\n",
        "    3: 1.0, # df\n",
        "    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n",
        "    5: 1.0, # nv\n",
        "    6: 1.0, # vasc\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4a5e3bc3cf44f1d4326c34ad880a302ba082e9d5",
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "3XD3N41fSvrm"
      },
      "source": [
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
        "                                   verbose=1, mode='max', min_lr=0.00001) #\n",
        "\n",
        "early_stop = tensorflow.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr, early_stop]\n",
        "\n",
        "history = model.fit_generator(train_batches, steps_per_epoch=train_steps,\n",
        "                              class_weight=class_weights,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=5, verbose=1,\n",
        "                              callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41BqoumFxVMO"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c3e43e3f2943db4be9d75831fe23661ae9deb44b",
        "id": "LK3EgL1gSvrq"
      },
      "source": [
        "### Evaluar el modelo utilizando el conjunto de valores de validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "710ee26097924153647ac432c8ade29383fe42f1",
        "id": "WD6ke0WwSvrr"
      },
      "source": [
        "# get the metric names so we can use evaulate_generator\n",
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "68603a5e8cb5e507db95074a07b552a61fa48e11",
        "id": "jltD8leKSvrw"
      },
      "source": [
        "# Here the the last epoch will be used.\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches,\n",
        "                        steps=len(df_val))\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "897f066da922d81fefa165a6b911a741c52ef7f5",
        "id": "whotXiNjSvrz"
      },
      "source": [
        "# Here the best epoch will be used.\n",
        "\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches,\n",
        "                        steps=len(df_val))\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c3fffba5e0aa9088cda1865c7b8d75d72c20d0f6",
        "id": "9AVhJhoRSvr7"
      },
      "source": [
        "### Trazar las curvas de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0cbd11ef4286a751ef2918361af035d356f341ae",
        "id": "JeTtqL7HSvr7"
      },
      "source": [
        "# display the loss and accuracy curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_top2_acc = history.history['top_2_accuracy']\n",
        "val_top2_acc = history.history['val_top_2_accuracy']\n",
        "train_top3_acc = history.history['top_3_accuracy']\n",
        "val_top3_acc = history.history['val_top_3_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
        "#plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
        "plt.title('Training and validation cat accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.plot(epochs, train_top2_acc, 'bo', label='Training top2 acc')\n",
        "#plt.plot(epochs, val_top2_acc, 'b', label='Validation top2 acc')\n",
        "plt.title('Training and validation top2 accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_top3_acc, 'bo', label='Training top3 acc')\n",
        "#plt.plot(epochs, val_top3_acc, 'b', label='Validation top3 acc')\n",
        "plt.title('Training and validation top3 accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = history.history['val_loss']\n",
        "val_loss"
      ],
      "metadata": {
        "id": "Z6qoop-HKS58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "4204e4056c8d12c1fee72b97912879cad4ee483f",
        "id": "P9r5QNCzSvsB"
      },
      "source": [
        "### Creando la matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "74a66905f7a2d702f3d2aad9abf9fe114b96f0ff",
        "id": "tgXd6LeaSvsC"
      },
      "source": [
        "# Get the labels of the test images.\n",
        "# Note that cats and dogs are in seperate folders therefore\n",
        "# the code below can get the labels depending on the folder the image is in.\n",
        "\n",
        "test_labels = test_batches.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "53f4b22617285e923f336cdb2ffcbe1f9ff5e5db",
        "_kg_hide-output": true,
        "id": "Q6DJMWfGSvsI"
      },
      "source": [
        "# We need these to plot the confusion matrix.\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d5113e039e8384b96595751e084f0c5ed677080a",
        "id": "D61LvRDFSvsO"
      },
      "source": [
        "# Print the label associated with each class\n",
        "test_batches.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "701dafc5874aa60a054a74c04170cb7e8d750e94",
        "id": "DqqJQimuSvsY"
      },
      "source": [
        "# make a prediction\n",
        "predictions = model.predict_generator(test_batches, steps=len(df_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "dcce17ac0488ff90d29b11592c9226ed1bb210fb",
        "id": "Ssa5p9JmSvse"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7cfd9bdbbd27e27d9c5de7c6593527686445ea89",
        "id": "95MNShN_Svsi"
      },
      "source": [
        "# Source: Scikit Learn website\n",
        "# http://scikit-learn.org/stable/auto_examples/\n",
        "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
        "# selection-plot-confusion-matrix-py\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8d499136cdb5fdf356515beb6e0cd1130ed584db",
        "id": "deDo1FpVSvsn"
      },
      "source": [
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "940b71bb2b37d847ba81dd67ca50c7fd5785fd35",
        "id": "zh_5JNBKSvsq"
      },
      "source": [
        "# argmax returns the index of the max value in a row\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "97c6b493c368ff6565782c1bb15827f5d349ef79",
        "id": "jl3IamUySvst"
      },
      "source": [
        "test_batches.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0ddbd33a93468075c64ba49188a6d272a5c7828f",
        "id": "MtJgCvQvSvs3"
      },
      "source": [
        "# Define the labels of the class indices. These need to match the\n",
        "# order shown above.\n",
        "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4c46f3f1d257241f96b4aac7eb96831ff8bbea33",
        "id": "FqMqaztOSvs7"
      },
      "source": [
        "# End of Model Building\n",
        "### ===================================================================================== ###\n",
        "# Convert the Model from Keras to Tensorflow.js"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11h0AdF30ktb"
      },
      "source": [
        "# Get the index of the class with the highest probability score\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the labels of the test images.\n",
        "y_true = test_batches.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVtYXtDG0pPJ"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n",
        "\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P_N4YVy0uH4"
      },
      "source": [
        "Recall = Given a class, will the classifier be able to detect it?\n",
        "\n",
        "Precision = Given a class prediction from a classifier, how likely is it to be correct?\n",
        "\n",
        "F1 Score = The harmonic mean of the recall and precision. Essentially, it punishes extreme values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7f9017d69bf0b84522e34841c1876b613cae1535",
        "id": "l8vYJM7TSvtE"
      },
      "source": [
        "### Install Tensorflow.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "2da93a52657b786a8eb7a0d5df6d6a2bcbd0f1c6",
        "_kg_hide-output": true,
        "id": "yzrSVqSJSvtF"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a85d7889e2bada2ebe3b84fc1571a89b1a66b7b0",
        "id": "DaJZx6bcSvtQ"
      },
      "source": [
        "### Convert the model from Keras to Tensorflowjs\n",
        "The conversion code below no longer works in kaggle kernels. I've left it in for reference.\n",
        "\n",
        "In order to convert this model the workaround is as follows:<br>\n",
        "1. Recreate the model using native Keras.<br>\n",
        "2. Use the command line conversion process to convert the model from Keras to Tensorflowjs.<br>\n",
        "Here's how to do that: https://www.youtube.com/watch?v=Kc2_x6pBYGE\n",
        "\n",
        "The above steps can be done in a kaggle kernel quite easily. Tensorflowjs is still fairly new so these type of bugs are not unusual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9977179251a2feb129a946028fb74d30b9eb7341",
        "id": "mqiIzehkSvtR"
      },
      "source": [
        "# create a directory to store the model files\n",
        "#os.mkdir('tfjs_dir')\n",
        "\n",
        "model.save('model.h5')\n",
        "\n",
        "# convert to Tensorflow.js\n",
        "\n",
        "\n",
        "# Error\n",
        "# AttributeError: module 'tensorflow.python.data.ops.dataset_ops'\n",
        "    # has no attribute 'UnaryDataset'\n",
        "\n",
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras model.h5 model/\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "tfjs.converters.save_keras_model(model.h5, 'tfjs_dir')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiFbz73bJERw"
      },
      "source": [
        "!zip -r model.zip model\n",
        "\n",
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7df391a2792ddfb7fa2a980776aeac744612f702",
        "id": "EfM1KGrjSvte"
      },
      "source": [
        "# check the the directory containing the model is available\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "71dd9a6a021d4ffcc159dafd52e7f86ecc6558cb",
        "id": "tliazVDpSvti"
      },
      "source": [
        "# view the files that make up the tensorflow.js model\n",
        "#os.listdir('tfjs_dir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "f774cd15c6de188d4bb150f25ab600e5cbc06031",
        "id": "7lTdYd88Svtn"
      },
      "source": [
        "# Delete the image data directory we created to prevent a Kaggle error.\n",
        "# Kaggle allows a max of 500 files to be saved.\n",
        "\n",
        "#shutil.rmtree('base_dir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "_uuid": "4b6056bb27006ebc85fb54bbc8b9b989bd756ff1",
        "id": "dPPd1pxuSvtt"
      },
      "source": [
        "### Resources\n",
        "\n",
        "These are some resources that I used:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d5f5d88e7cda18fb86c7e9715e488536e4424673",
        "id": "HbrGB3xdSvtu"
      },
      "source": [
        "1. Excellent tutorial series by deeplizard on how to use Mobilenet with Tensorflow.js<br>\n",
        "https://www.youtube.com/watch?v=HEQDRWMK6yY\n",
        "\n",
        "2. Tutorial by Minsuk Heo on Accuracy, Precision and F1 Score<br>\n",
        "https://www.youtube.com/watch?v=HBi-P5j0Kec\n",
        "\n",
        "3. Tutorial by Data School on how to evaluate a classifier<br>\n",
        "https://www.youtube.com/watch?v=85dtiMz9tSo\n",
        "\n",
        "3. Tensorflow.js gallery of projects<br>\n",
        "https://github.com/tensorflow/tfjs/blob/master/GALLERY.md\n",
        "\n"
      ]
    }
  ]
}